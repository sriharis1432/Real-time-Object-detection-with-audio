{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "# For vedio --> object detection with audio"
      ],
      "metadata": {
        "id": "RRpU5yxNipQ_"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# !pip install opencv-contrib-python # some people ask the difference between this and opencv-python and opencv-python contains the main packages wheras the other\n",
        "                                    # contains both main modules and contrib/extra modules\n",
        "# !pip install cvlib               # for object detection\n",
        "# !pip install gtts                # convert text to speech\n",
        "# !pip install playsound           # generate the sound for file\n",
        "# !pip3 install PyObjC`            # if you want playsound to run more efficiently.\n",
        "\n",
        "import cv2\n",
        "import cvlib as cv\n",
        "from cvlib.object_detection import draw_bbox\n",
        "from gtts import gTTS\n",
        "from playsound import playsound\n",
        "\n",
        "def speech(text):\n",
        "    print(text)\n",
        "    language = \"en\"\n",
        "    output = gTTS(text=text, lang=language, slow=False)\n",
        "\n",
        "    output.save(\".output.mp3\")\n",
        "    playsound(\"output.mp3\")\n",
        "\n",
        "\n",
        "video = cv2.VideoCapture('/content/DOC-20220501-WA0041.')\n",
        "labels = []\n",
        "\n",
        "while True:\n",
        "    ret, frame = video.read()\n",
        "\n",
        "    if not ret:\n",
        "      print('error: filed to grab frame')\n",
        "      break\n",
        "    # Bounding box.\n",
        "    # the cvlib library has learned some basic objects using object learning\n",
        "    # usually it takes around 800 images for it to learn what a phone is.\n",
        "    bbox, label, conf = cv.detect_common_objects(frame)  # Detects common objects in the frame, returning bounding boxes, labels, and confidence scores.\n",
        "\n",
        "    output_image = draw_bbox(frame, bbox, label, conf)   # Draws bounding boxes around detected objects and labels them.\n",
        "\n",
        "    cv2.imshow(\"Detection\", output_image)\n",
        "\n",
        "    for item in label:\n",
        "        if item in labels:\n",
        "            pass\n",
        "        else:\n",
        "            labels.append(item)\n",
        "\n",
        "    if cv2.waitKey(1) & 0xFF == ord(\"q\"):    # Breaks the loop if 'q' is pressed.\n",
        "        break\n",
        "\n",
        "i = 0\n",
        "new_sentence = []\n",
        "for label in labels:\n",
        "    if i == 0:\n",
        "        new_sentence.append(f\"I found a {label}, and, \")\n",
        "    else:\n",
        "        new_sentence.append(f\"a {label},\")\n",
        "\n",
        "    i += 1\n",
        "\n",
        "speech(\" \".join(new_sentence))"
      ],
      "metadata": {
        "id": "vXAY8CWYTG89"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import cv2\n",
        "import cvlib as cv\n",
        "from cvlib.object_detection import draw_bbox\n",
        "from gtts import gTTS\n",
        "from playsound import playsound\n",
        "\n",
        "def speech(text):\n",
        "  for i,text in enumerate(text):\n",
        "    print(text)\n",
        "    language = \"en\"\n",
        "    output = gTTS(text=text, lang=language, slow=False)\n",
        "    output.save(f\"{i}.mp3\")\n",
        "\n",
        "text=['man is good and women is bad','mouns is good']\n",
        "speech(text)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "RtUfFhQji5T9",
        "outputId": "2276983e-47d8-4ee7-eb1d-66d3bcc83c73"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "man is good and women is bad\n",
            "mouns is good\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import cv2\n",
        "import cvlib as cv\n",
        "from cvlib.object_detection import draw_bbox\n",
        "from gtts import gTTS\n",
        "from playsound import playsound\n",
        "\n",
        "def speech(text):\n",
        "    print(text)\n",
        "    language = \"en\"\n",
        "    output = gTTS(text=text, lang=language, slow=False)\n",
        "    output.save(\"output.mp3\")\n",
        "    playsound(\"output.mp3\")\n",
        "\n",
        "# Paths to YOLO files\n",
        "config_path = '/content/yolov3.cfg'\n",
        "weights_path = '/content/yolov3 (1).weights'\n",
        "names_path = '/content/coco.names'\n",
        "\n",
        "# Load YOLO\n",
        "net = cv2.dnn.readNetFromDarknet(config_path, weights_path)\n",
        "\n",
        "# image=cv2.imread('/content/117kb.jpg')\n",
        "video = cv2.VideoCapture(0)\n",
        "labels = []\n",
        "\n",
        "while True:\n",
        "    ret, frame = video.read()\n",
        "    if not ret:\n",
        "        print(\"Failed to grab frame\")\n",
        "        break\n",
        "\n",
        "    # Detect common objects in the frame\n",
        "    bbox, label, conf = cv.detect_common_objects(frame, model='yolov3', enable_gpu=False)\n",
        "\n",
        "    output_image = draw_bbox(frame, bbox, label, conf)\n",
        "    cv2.imshow(\"Detection\", output_image)\n",
        "\n",
        "    for item in label:\n",
        "        if item not in labels:\n",
        "            labels.append(item)\n",
        "\n",
        "    if cv2.waitKey(1) & 0xFF == ord(\"q\"):\n",
        "        break\n",
        "\n",
        "# video.release()\n",
        "# cv2.destroyAllWindows()\n",
        "\n",
        "i = 0\n",
        "new_sentence = []\n",
        "for label in labels:\n",
        "    if i == 0:\n",
        "        new_sentence.append(f\"I found a {label}, and, \")\n",
        "    else:\n",
        "        new_sentence.append(f\"a {label},\")\n",
        "    i += 1\n",
        "\n",
        "# speech(\" \".join(new_sentence))\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "KK6bJP9bk9I3",
        "outputId": "85c965bc-47ae-4694-acda-e2aff6aa4cf1"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Failed to grab frame\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# For Image, --> object detection and audio"
      ],
      "metadata": {
        "id": "T40qrMDxi7ri"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import cv2\n",
        "\n",
        "video = cv2.VideoCapture(0)  # Use 0 for the default webcam\n",
        "while True:\n",
        "    ret, frame = video.read()\n",
        "    if not ret:\n",
        "        print(\"Failed to grab frame\")\n",
        "        break\n",
        "    cv2.imshow(\"Frame\", frame)\n",
        "    if cv2.waitKey(1) & 0xFF == ord('q'): # Exit on 'q' key press\n",
        "        break\n",
        "\n",
        "# Release the video capture object and close all OpenCV windows\n",
        "video.release()\n",
        "cv2.destroyAllWindows()\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "BeCEhNmIeTDS",
        "outputId": "eea6abc1-50ca-45d9-ca31-14b0033be3e5"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Failed to grab frame\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Required installations\n",
        "# pip install opencv-contrib-python\n",
        "#!pip install cvlib\n",
        "# !pip install gtts\n",
        "# !pip install playsound\n",
        "\n",
        "import cv2\n",
        "import cvlib as cv\n",
        "from cvlib.object_detection import draw_bbox\n",
        "from gtts import gTTS\n",
        "from playsound import playsound\n",
        "\n",
        "def speech(text):\n",
        "    print(text)\n",
        "    language = \"en\"\n",
        "    output = gTTS(text=text, lang=language, slow=False)\n",
        "    output.save(\"output.mp3\")\n",
        "    playsound(\"output.mp3\")\n",
        "\n",
        "# Path to the image file\n",
        "image_path = \"/content/117kb.jpg\"\n",
        "\n",
        "# Load the image\n",
        "image = cv2.imread(image_path)\n",
        "labels = []\n",
        "\n",
        "# Bounding box detection\n",
        "bbox, label, conf = cv.detect_common_objects(image) # Detects common objects in the frame, returning bounding boxes, labels, and confidence scores.\n",
        "\n",
        "# Draw bounding boxes on the image\n",
        "output_image = draw_bbox(image, bbox, label, conf)\n",
        "\n",
        "# Display the image with bounding boxes\n",
        "cv2.imshow(\"Detection\", output_image)\n",
        "cv2.waitKey(0)  # Wait for a key press to close the image window\n",
        "cv2.destroyAllWindows()\n",
        "\n",
        "# Collect unique labels\n",
        "for item in label:\n",
        "    if item in labels:\n",
        "        pass\n",
        "    else:\n",
        "        labels.append(item)\n",
        "\n",
        "# Generate and play the speech description\n",
        "i = 0\n",
        "new_sentence = []\n",
        "for label in labels:\n",
        "    if i == 0:\n",
        "        new_sentence.append(f\"I found a {label}, and, \")\n",
        "    else:\n",
        "        new_sentence.append(f\"a {label},\")\n",
        "    i += 1\n",
        "\n",
        "speech(\" \".join(new_sentence))\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ZtDeWQCorl9N",
        "outputId": "632a2c1a-35e5-4a01-ba83-0bf3ac0cd836"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "man is good and women is bad\n",
            "mouns is good\n"
          ]
        }
      ]
    }
  ]
}